{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Biolink Predicate Granularity Explorer\n",
    "\n",
    "This notebook explores the biolink model predicate hierarchy to design a granularity-based filtering system.\n",
    "\n",
    "**Goal**: Allow users to exclude vague predicates (like `related_to`) while keeping more specific ones.\n",
    "\n",
    "**Workflow:**\n",
    "1. Fetch/cache biolink-model.yaml (version-aware)\n",
    "2. Parse predicate hierarchy from `is_a` relationships\n",
    "3. Build tree structure with treelib\n",
    "4. Analyze depth distribution\n",
    "5. Visualize \"cuts\" at different granularity levels\n",
    "6. Test filtering against real TCT MetaKG predicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Set, Tuple\n",
    "import yaml\n",
    "from treelib import Tree\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = Path(\"../data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "BIOLINK_CACHE_PATH = DATA_DIR / \"biolink-model.yaml\"\n",
    "BIOLINK_VERSION_PATH = DATA_DIR / \"biolink-model-version.txt\"\n",
    "GITHUB_REPO = \"biolink/biolink-model\"\n",
    "\n",
    "# Toggle to exclude literature co-occurrence predicates\n",
    "EXCLUDE_LITERATURE_COOCCURRENCE = False\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR.resolve()}\")\n",
    "print(f\"Cache path: {BIOLINK_CACHE_PATH}\")\n",
    "print(f\"Exclude literature co-occurrence: {EXCLUDE_LITERATURE_COOCCURRENCE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 2. Version-Aware Biolink Model Fetching\n",
    "\n",
    "- Checks GitHub for latest release tag\n",
    "- Compares to locally cached version\n",
    "- Updates cache only if newer version available\n",
    "- Graceful fallback on network issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_biolink_version() -> Optional[str]:\n",
    "    \"\"\"Fetch latest release tag from GitHub API.\"\"\"\n",
    "    try:\n",
    "        resp = requests.get(\n",
    "            f\"https://api.github.com/repos/{GITHUB_REPO}/releases/latest\",\n",
    "            timeout=10\n",
    "        )\n",
    "        if resp.status_code == 200:\n",
    "            return resp.json().get(\"tag_name\")\n",
    "        else:\n",
    "            print(f\"Warning: GitHub API returned status {resp.status_code}\")\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Warning: Could not check GitHub for updates: {e}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_local_version() -> Optional[str]:\n",
    "    \"\"\"Read cached version if exists.\"\"\"\n",
    "    if BIOLINK_VERSION_PATH.exists():\n",
    "        return BIOLINK_VERSION_PATH.read_text().strip()\n",
    "    return None\n",
    "\n",
    "\n",
    "def fetch_biolink_model(version: str) -> str:\n",
    "    \"\"\"Fetch biolink-model.yaml for specific version/tag.\"\"\"\n",
    "    url = f\"https://raw.githubusercontent.com/{GITHUB_REPO}/{version}/biolink-model.yaml\"\n",
    "    print(f\"Fetching from: {url}\")\n",
    "    resp = requests.get(url, timeout=60)\n",
    "    resp.raise_for_status()\n",
    "    return resp.text\n",
    "\n",
    "\n",
    "def load_biolink_model() -> dict:\n",
    "    \"\"\"Load biolink model, updating cache if newer version available.\"\"\"\n",
    "    local_version = get_local_version()\n",
    "    latest_version = get_latest_biolink_version()\n",
    "\n",
    "    need_update = False\n",
    "    \n",
    "    if latest_version:\n",
    "        if local_version is None:\n",
    "            print(f\"No local cache found. Downloading {latest_version}...\")\n",
    "            need_update = True\n",
    "        elif latest_version != local_version:\n",
    "            print(f\"Update available: {local_version} -> {latest_version}\")\n",
    "            need_update = True\n",
    "        else:\n",
    "            print(f\"Local cache is current: {local_version}\")\n",
    "    else:\n",
    "        print(\"Could not check for updates. Using local cache if available.\")\n",
    "\n",
    "    if need_update and latest_version:\n",
    "        try:\n",
    "            yaml_content = fetch_biolink_model(latest_version)\n",
    "            BIOLINK_CACHE_PATH.write_text(yaml_content)\n",
    "            BIOLINK_VERSION_PATH.write_text(latest_version)\n",
    "            print(f\"Successfully cached version {latest_version}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Failed to download update: {e}\")\n",
    "            if not BIOLINK_CACHE_PATH.exists():\n",
    "                raise RuntimeError(\"No local cache and cannot download biolink model\")\n",
    "            print(\"Falling back to existing cache.\")\n",
    "\n",
    "    if not BIOLINK_CACHE_PATH.exists():\n",
    "        raise RuntimeError(\n",
    "            f\"No biolink-model.yaml found at {BIOLINK_CACHE_PATH}. \"\n",
    "            \"Check network connection.\"\n",
    "        )\n",
    "\n",
    "    print(f\"Loading from: {BIOLINK_CACHE_PATH}\")\n",
    "    return yaml.safe_load(BIOLINK_CACHE_PATH.read_text())\n",
    "\n",
    "\n",
    "# Load the model\n",
    "biolink_model = load_biolink_model()\n",
    "print(f\"\\nLoaded biolink model with {len(biolink_model.get('slots', {}))} slots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 3. Parse Predicates from Biolink Model\n",
    "\n",
    "Extract predicates (slots) that have `is_a` relationships forming the hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_predicate_name(name: str) -> str:\n",
    "    \"\"\"Normalize predicate name: spaces to underscores, lowercase.\"\"\"\n",
    "    return name.replace(\" \", \"_\").lower().strip()\n",
    "\n",
    "\n",
    "def extract_predicates(model: dict) -> Dict[str, Dict]:\n",
    "    \"\"\"Extract predicates (slots) and their hierarchy relationships.\n",
    "\n",
    "    Filters to only include slots that are part of the predicate hierarchy\n",
    "    (those that eventually trace back to 'related_to' via is_a).\n",
    "    \n",
    "    Note: Biolink model uses spaces in slot names (e.g., \"related to\"),\n",
    "    but the API uses underscores (e.g., \"related_to\"). We normalize to underscores.\n",
    "    \"\"\"\n",
    "    slots = model.get(\"slots\", {})\n",
    "    predicates = {}\n",
    "\n",
    "    # First pass: collect all slots - normalize names to use underscores\n",
    "    for name, definition in slots.items():\n",
    "        if definition is None:\n",
    "            continue\n",
    "\n",
    "        # Normalize the slot name (spaces -> underscores)\n",
    "        normalized_name = normalize_predicate_name(name)\n",
    "        \n",
    "        is_a_raw = definition.get(\"is_a\")\n",
    "        # Also normalize the parent name if present\n",
    "        is_a = normalize_predicate_name(is_a_raw) if is_a_raw else None\n",
    "        \n",
    "        slot_uri = definition.get(\"slot_uri\", \"\")\n",
    "\n",
    "        # Always include 'related_to' as root, plus any slot with is_a\n",
    "        if normalized_name == \"related_to\" or is_a:\n",
    "            predicates[normalized_name] = {\n",
    "                \"is_a\": is_a,\n",
    "                \"description\": definition.get(\"description\", \"\"),\n",
    "                \"inverse\": normalize_predicate_name(definition.get(\"inverse\", \"\")) if definition.get(\"inverse\") else None,\n",
    "                \"symmetric\": definition.get(\"symmetric\", False),\n",
    "                \"slot_uri\": slot_uri,\n",
    "                \"abstract\": definition.get(\"abstract\", False),\n",
    "                \"original_name\": name,  # Keep original for reference\n",
    "            }\n",
    "\n",
    "    print(f\"First pass: found {len(predicates)} slots with is_a relationships\")\n",
    "    \n",
    "    # Check if related_to was found\n",
    "    if \"related_to\" in predicates:\n",
    "        print(\"  ✓ Found 'related_to' root predicate\")\n",
    "    else:\n",
    "        print(\"  ✗ WARNING: 'related_to' not found!\")\n",
    "\n",
    "    # Second pass: filter to only predicates in the related_to hierarchy\n",
    "    def traces_to_related_to(name: str, visited: set = None) -> bool:\n",
    "        \"\"\"Check if predicate eventually inherits from related_to.\"\"\"\n",
    "        if visited is None:\n",
    "            visited = set()\n",
    "        if name in visited:\n",
    "            return False  # Cycle detection\n",
    "        visited.add(name)\n",
    "\n",
    "        if name == \"related_to\":\n",
    "            return True\n",
    "        if name not in predicates:\n",
    "            return False\n",
    "        parent = predicates[name].get(\"is_a\")\n",
    "        if parent:\n",
    "            return traces_to_related_to(parent, visited)\n",
    "        return False\n",
    "\n",
    "    # Filter to related_to hierarchy only\n",
    "    related_to_predicates = {}\n",
    "    for name, info in predicates.items():\n",
    "        if name == \"related_to\" or traces_to_related_to(name):\n",
    "            related_to_predicates[name] = info\n",
    "\n",
    "    return related_to_predicates\n",
    "\n",
    "\n",
    "predicates = extract_predicates(biolink_model)\n",
    "print(f\"\\nExtracted {len(predicates)} predicates in related_to hierarchy\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample predicates:\")\n",
    "for name, info in list(predicates.items())[:10]:\n",
    "    print(f\"  {name}: is_a={info['is_a']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 4. Build Predicate Hierarchy Tree\n",
    "\n",
    "Use treelib to create a navigable tree structure from the `is_a` relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_predicate_tree(predicates: Dict[str, Dict]) -> Tree:\n",
    "    \"\"\"Build treelib Tree from predicate is_a relationships.\"\"\"\n",
    "    tree = Tree()\n",
    "\n",
    "    # Track which nodes have been added\n",
    "    added = set()\n",
    "\n",
    "    def add_node(name: str, parent: Optional[str] = None):\n",
    "        \"\"\"Recursively add node, ensuring parent exists first.\"\"\"\n",
    "        if name in added:\n",
    "            return\n",
    "        \n",
    "        # If parent specified and not yet added, add parent first\n",
    "        if parent and parent not in added:\n",
    "            parent_info = predicates.get(parent, {})\n",
    "            grandparent = parent_info.get(\"is_a\")\n",
    "            # Only add parent if it's in our predicate set\n",
    "            if parent in predicates:\n",
    "                add_node(parent, grandparent)\n",
    "\n",
    "        # Determine actual parent for tree (must be in added set)\n",
    "        tree_parent = parent if parent in added else None\n",
    "\n",
    "        tree.create_node(\n",
    "            tag=name,\n",
    "            identifier=name,\n",
    "            parent=tree_parent,\n",
    "            data=predicates.get(name, {})\n",
    "        )\n",
    "        added.add(name)\n",
    "\n",
    "    # Add all predicates\n",
    "    for name, info in predicates.items():\n",
    "        add_node(name, info.get(\"is_a\"))\n",
    "\n",
    "    return tree\n",
    "\n",
    "\n",
    "predicate_tree = build_predicate_tree(predicates)\n",
    "print(f\"Built tree with {len(predicate_tree)} nodes\")\n",
    "\n",
    "# Find roots (nodes with no parent)\n",
    "roots = [node.identifier for node in predicate_tree.all_nodes() \n",
    "         if predicate_tree.parent(node.identifier) is None]\n",
    "print(f\"Root nodes: {roots}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 5. Visualize Full Predicate Tree\n",
    "\n",
    "Display the complete hierarchy using treelib's built-in display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"BIOLINK PREDICATE HIERARCHY\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Show tree from related_to root\n",
    "if \"related_to\" in [n.identifier for n in predicate_tree.all_nodes()]:\n",
    "    predicate_tree.show(idhidden=False)\n",
    "else:\n",
    "    # Show all roots if related_to not found\n",
    "    for root in roots:\n",
    "        print(f\"\\n--- Tree rooted at: {root} ---\")\n",
    "        predicate_tree.show(nid=root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 6. Calculate Predicate Depths\n",
    "\n",
    "Compute the depth of each predicate from the root (`related_to`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_depths(tree: Tree) -> Dict[str, int]:\n",
    "    \"\"\"Calculate depth of each predicate from root.\"\"\"\n",
    "    depths = {}\n",
    "\n",
    "    def calculate_depth(node_id: str, current_depth: int = 0):\n",
    "        depths[node_id] = current_depth\n",
    "        for child in tree.children(node_id):\n",
    "            calculate_depth(child.identifier, current_depth + 1)\n",
    "\n",
    "    # Start from all roots\n",
    "    for node in tree.all_nodes():\n",
    "        if tree.parent(node.identifier) is None:\n",
    "            calculate_depth(node.identifier, 0)\n",
    "\n",
    "    return depths\n",
    "\n",
    "\n",
    "predicate_depths = get_all_depths(predicate_tree)\n",
    "\n",
    "# Analyze depth distribution\n",
    "depth_counts = {}\n",
    "for pred, depth in predicate_depths.items():\n",
    "    depth_counts[depth] = depth_counts.get(depth, 0) + 1\n",
    "\n",
    "print(\"Predicate Depth Distribution:\")\n",
    "print(\"-\" * 50)\n",
    "for depth in sorted(depth_counts.keys()):\n",
    "    count = depth_counts[depth]\n",
    "    bar = \"#\" * min(count, 50)\n",
    "    print(f\"  Depth {depth}: {count:3d} predicates  {bar}\")\n",
    "\n",
    "max_depth = max(predicate_depths.values()) if predicate_depths else 0\n",
    "print(f\"\\nMax depth: {max_depth}\")\n",
    "\n",
    "# Show examples at each depth\n",
    "print(\"\\nExamples at each depth:\")\n",
    "print(\"-\" * 50)\n",
    "for depth in sorted(depth_counts.keys()):\n",
    "    examples = [p for p, d in predicate_depths.items() if d == depth][:5]\n",
    "    print(f\"  Depth {depth}: {', '.join(examples)}{'...' if depth_counts[depth] > 5 else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 7. Define Granularity Filtering Functions\n",
    "\n",
    "Functions to filter predicates based on depth (granularity level)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicates_at_min_depth(depths: Dict[str, int], min_depth: int) -> Set[str]:\n",
    "    \"\"\"Return predicates at or deeper than min_depth.\"\"\"\n",
    "    return {pred for pred, depth in depths.items() if depth >= min_depth}\n",
    "\n",
    "\n",
    "def get_predicates_excluded_at_depth(depths: Dict[str, int], min_depth: int) -> Set[str]:\n",
    "    \"\"\"Return predicates excluded (shallower than min_depth).\"\"\"\n",
    "    return {pred for pred, depth in depths.items() if depth < min_depth}\n",
    "\n",
    "\n",
    "def filter_predicates_by_granularity(\n",
    "    predicates_list: List[str],\n",
    "    min_depth: int,\n",
    "    depths: Dict[str, int],\n",
    "    exclude_literature: bool = False\n",
    ") -> List[str]:\n",
    "    \"\"\"Filter predicate list by granularity level.\n",
    "    \n",
    "    Args:\n",
    "        predicates_list: List of predicates (may include biolink: prefix)\n",
    "        min_depth: Minimum depth required (0 = all, 1 = exclude root, etc.)\n",
    "        depths: Dict mapping predicate names to their depths\n",
    "        exclude_literature: If True, exclude predicates with 'literature' in name\n",
    "    \n",
    "    Returns:\n",
    "        Filtered list of predicates\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for pred in predicates_list:\n",
    "        # Normalize: remove biolink: prefix if present\n",
    "        pred_name = pred.replace(\"biolink:\", \"\").strip()\n",
    "\n",
    "        # Check depth (predicates not in our tree are excluded)\n",
    "        if pred_name not in depths:\n",
    "            continue\n",
    "        if depths[pred_name] < min_depth:\n",
    "            continue\n",
    "\n",
    "        # Check literature exclusion\n",
    "        if exclude_literature and \"literature\" in pred_name.lower():\n",
    "            continue\n",
    "\n",
    "        result.append(pred)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Test at different granularity levels\n",
    "print(\"Predicates remaining at each granularity level:\")\n",
    "print(\"-\" * 60)\n",
    "for level in range(min(max_depth + 1, 8)):\n",
    "    remaining = get_predicates_at_min_depth(predicate_depths, level)\n",
    "    excluded = get_predicates_excluded_at_depth(predicate_depths, level)\n",
    "    print(f\"Level {level}: {len(remaining):3d} allowed, {len(excluded):3d} excluded\")\n",
    "    if excluded:\n",
    "        excluded_list = sorted(excluded)[:5]\n",
    "        suffix = \"...\" if len(excluded) > 5 else \"\"\n",
    "        print(f\"         Excluded: {', '.join(excluded_list)}{suffix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 8. Visualize Tree \"Cuts\" at Different Levels\n",
    "\n",
    "Show what the predicate tree looks like when cut at different granularity levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tree_at_depth(\n",
    "    tree: Tree, \n",
    "    depths: Dict[str, int], \n",
    "    min_depth: int, \n",
    "    max_display: int = 100\n",
    "):\n",
    "    \"\"\"Show subtree of predicates allowed at given granularity.\"\"\"\n",
    "    allowed = get_predicates_at_min_depth(depths, min_depth)\n",
    "    excluded = get_predicates_excluded_at_depth(depths, min_depth)\n",
    "\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(f\"GRANULARITY LEVEL {min_depth}: {len(allowed)} predicates allowed\")\n",
    "    \n",
    "    # Show excluded predicates (truncate if too many)\n",
    "    if len(excluded) <= 10:\n",
    "        print(f\"Excluded ({len(excluded)}): {', '.join(sorted(excluded))}\")\n",
    "    else:\n",
    "        excluded_sample = ', '.join(sorted(excluded)[:10])\n",
    "        print(f\"Excluded ({len(excluded)}): {excluded_sample}...\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    if len(allowed) == 0:\n",
    "        print(\"(No predicates at this level)\")\n",
    "        return\n",
    "\n",
    "    # Build subtree of allowed predicates\n",
    "    if len(allowed) <= max_display:\n",
    "        # Use a forest approach - create artificial root to hold multiple trees\n",
    "        subtree = Tree()\n",
    "        subtree.create_node(\"ALLOWED_PREDICATES\", \"root\")\n",
    "        added_to_subtree = {\"root\"}\n",
    "        \n",
    "        # Sort by depth to ensure parents processed before children\n",
    "        sorted_allowed = sorted(allowed, key=lambda x: depths.get(x, 0))\n",
    "        \n",
    "        for pred in sorted_allowed:\n",
    "            if pred in added_to_subtree:\n",
    "                continue\n",
    "            \n",
    "            # Find closest allowed ancestor in original tree\n",
    "            parent_id = None\n",
    "            current = tree.parent(pred)\n",
    "            while current:\n",
    "                if current.identifier in allowed and current.identifier in added_to_subtree:\n",
    "                    parent_id = current.identifier\n",
    "                    break\n",
    "                current = tree.parent(current.identifier)\n",
    "            \n",
    "            # If no allowed ancestor found, attach to artificial root\n",
    "            if parent_id is None:\n",
    "                parent_id = \"root\"\n",
    "\n",
    "            subtree.create_node(pred, pred, parent=parent_id)\n",
    "            added_to_subtree.add(pred)\n",
    "\n",
    "        # Show the tree (skip the artificial root label)\n",
    "        subtree.show()\n",
    "    else:\n",
    "        print(f\"(Too many to display full tree - showing depth {min_depth} predicates only)\")\n",
    "        # Show just the predicates at exactly this depth level\n",
    "        at_this_depth = [p for p, d in depths.items() if d == min_depth]\n",
    "        print(f\"\\nPredicates at exactly depth {min_depth} ({len(at_this_depth)}):\")\n",
    "        for pred in sorted(at_this_depth)[:30]:\n",
    "            print(f\"  - {pred}\")\n",
    "        if len(at_this_depth) > 30:\n",
    "            print(f\"  ... and {len(at_this_depth) - 30} more\")\n",
    "\n",
    "\n",
    "# Show cuts at key levels\n",
    "for level in range(min(max_depth + 1, 5)):\n",
    "    show_tree_at_depth(predicate_tree, predicate_depths, level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 9. Test with Real TCT MetaKG Data\n",
    "\n",
    "Load the Translator MetaKG and test how granularity filtering affects real predicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TCT if available\n",
    "try:\n",
    "    from TCT import TCT\n",
    "    from TCT import translator_metakg\n",
    "\n",
    "    print(\"Loading Translator MetaKG...\")\n",
    "    print(\"(This may take 1-2 minutes)\\n\")\n",
    "    \n",
    "    APInames, metaKG, _ = translator_metakg.load_translator_resources()\n",
    "\n",
    "    # Get all predicates in MetaKG\n",
    "    metakg_predicates = list(set(metaKG[\"Predicate\"]))\n",
    "    print(f\"MetaKG contains {len(metakg_predicates)} unique predicates\")\n",
    "    \n",
    "    # Show sample\n",
    "    print(f\"\\nSample MetaKG predicates:\")\n",
    "    for pred in sorted(metakg_predicates)[:10]:\n",
    "        pred_name = pred.replace(\"biolink:\", \"\")\n",
    "        depth = predicate_depths.get(pred_name, \"N/A\")\n",
    "        print(f\"  {pred} (depth: {depth})\")\n",
    "\n",
    "    # Test filtering at each level\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Filtering MetaKG predicates by granularity:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for level in range(min(max_depth + 1, 6)):\n",
    "        # Without literature exclusion\n",
    "        filtered = filter_predicates_by_granularity(\n",
    "            metakg_predicates,\n",
    "            level,\n",
    "            predicate_depths,\n",
    "            exclude_literature=False\n",
    "        )\n",
    "        \n",
    "        # With literature exclusion\n",
    "        filtered_no_lit = filter_predicates_by_granularity(\n",
    "            metakg_predicates,\n",
    "            level,\n",
    "            predicate_depths,\n",
    "            exclude_literature=True\n",
    "        )\n",
    "        \n",
    "        pct = len(filtered) / len(metakg_predicates) * 100 if metakg_predicates else 0\n",
    "        pct_no_lit = len(filtered_no_lit) / len(metakg_predicates) * 100 if metakg_predicates else 0\n",
    "        \n",
    "        print(f\"Level {level}: {len(filtered):3d} ({pct:5.1f}%)  |  excl. lit: {len(filtered_no_lit):3d} ({pct_no_lit:5.1f}%)\")\n",
    "\n",
    "    TCT_AVAILABLE = True\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"TCT not available - skipping MetaKG analysis\")\n",
    "    print(f\"Error: {e}\")\n",
    "    TCT_AVAILABLE = False\n",
    "    metakg_predicates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicates of interest\n",
    "predicates_of_interest = [\n",
    "    \"related_to\",\n",
    "    \"associated_with\",\n",
    "    \"correlated_with\",\n",
    "    \"occurs_together_in_literature_with\",\n",
    "    \"interacts_with\",\n",
    "    \"physically_interacts_with\",\n",
    "    \"directly_physically_interacts_with\",\n",
    "    \"affects\",\n",
    "    \"regulates\",\n",
    "    \"causes\",\n",
    "    \"contributes_to\",\n",
    "    \"treats\",\n",
    "    \"gene_associated_with_condition\",\n",
    "    \"genetically_associated_with\",\n",
    "    \"in_clinical_trials_for\",\n",
    "    \"has_part\"\n",
    "]\n",
    "\n",
    "print(\"Predicates of Interest - Depth Analysis:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Predicate':<45} {'Depth':>6} {'In MetaKG':>10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for pred in predicates_of_interest:\n",
    "    depth = predicate_depths.get(pred, \"N/A\")\n",
    "    in_metakg = \"Yes\" if f\"biolink:{pred}\" in metakg_predicates or pred in metakg_predicates else \"No\"\n",
    "    print(f\"{pred:<45} {str(depth):>6} {in_metakg:>10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 10. Analyze Specific Predicates of Interest\n",
    "\n",
    "Look at specific predicates that might be problematic or useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 11. Summary & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cell-22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SUMMARY: PREDICATE GRANULARITY LEVELS\n",
      "======================================================================\n",
      "\n",
      "\n",
      " Level  Allowed  Excluded                                                   Excluded Examples\n",
      "     0      245         0                                                              (none)\n",
      "     1      244         1                                                          related_to\n",
      "     2      238         7 composed_primarily_of, disease_has_location, location_of_disease...\n",
      "     3      143       102                         active_in, acts_upstream_of, affected_by...\n",
      "     4       48       197               active_in, actively_involved_in, actively_involves...\n",
      "     5        6       239               active_in, actively_involved_in, actively_involves...\n",
      "     6        1       244               active_in, actively_involved_in, actively_involves...\n",
      "\n",
      "======================================================================\n",
      "CONFIGURATION NOTES\n",
      "======================================================================\n",
      "\n",
      "- EXCLUDE_LITERATURE_COOCCURRENCE = False\n",
      "- Level 0 = All predicates (most permissive, includes 'related_to')\n",
      "- Level 1 = Exclude 'related_to' (the most vague predicate)\n",
      "- Level 2+ = Increasingly specific predicates only\n",
      "- Max available level: 6\n",
      "\n",
      "======================================================================\n",
      "NEXT STEPS\n",
      "======================================================================\n",
      "\n",
      "1. Review the tree cuts above to decide on granularity presets\n",
      "2. Consider which levels make biological sense for your use case\n",
      "3. Decide on UI: slider vs named presets (\"All\", \"Moderate\", \"Specific\")\n",
      "4. Implement predicate filtering in trapi_client.py\n",
      "5. Add UI selector in app.py (similar to intermediate_types)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"SUMMARY: PREDICATE GRANULARITY LEVELS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create summary table\n",
    "summary_data = []\n",
    "for level in range(min(max_depth + 1, 7)):\n",
    "    allowed = get_predicates_at_min_depth(predicate_depths, level)\n",
    "    excluded = get_predicates_excluded_at_depth(predicate_depths, level)\n",
    "    \n",
    "    # Get excluded examples\n",
    "    excluded_examples = \", \".join(sorted(excluded)[:3])\n",
    "    if len(excluded) > 3:\n",
    "        excluded_examples += \"...\"\n",
    "    \n",
    "    summary_data.append({\n",
    "        \"Level\": level,\n",
    "        \"Allowed\": len(allowed),\n",
    "        \"Excluded\": len(excluded),\n",
    "        \"Excluded Examples\": excluded_examples if excluded else \"(none)\"\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CONFIGURATION NOTES\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n- EXCLUDE_LITERATURE_COOCCURRENCE = {EXCLUDE_LITERATURE_COOCCURRENCE}\")\n",
    "print(\"- Level 0 = All predicates (most permissive, includes 'related_to')\")\n",
    "print(\"- Level 1 = Exclude 'related_to' (the most vague predicate)\")\n",
    "print(\"- Level 2+ = Increasingly specific predicates only\")\n",
    "print(f\"- Max available level: {max_depth}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "1. Review the tree cuts above to decide on granularity presets\n",
    "2. Consider which levels make biological sense for your use case\n",
    "3. Decide on UI: slider vs named presets (\"All\", \"Moderate\", \"Specific\")\n",
    "4. Implement predicate filtering in trapi_client.py\n",
    "5. Add UI selector in app.py (similar to intermediate_types)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9161ae98-9e4b-4cda-9d02-2066a49b1763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
